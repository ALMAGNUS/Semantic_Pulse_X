#!/usr/bin/env python3
"""
Collecte YouTube sp√©cifique - Hugo Decrypte - Semantic Pulse X
Collecte les donn√©es d'une cha√Æne YouTube sp√©cifique
"""

import os
import requests
import logging
import json
from pathlib import Path
from datetime import datetime
import time
import pandas as pd
from dotenv import load_dotenv

# Chargement des variables d'environnement
load_dotenv()

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HugoYouTubeCollector:
    """Collecteur sp√©cialis√© pour la cha√Æne Hugo Decrypte"""
    
    def __init__(self):
        self.api_key = os.getenv('YOUTUBE_API_KEY')
        self.channel_id = "UCAcAnMF0OrCtUep3Y4M-ZPw"  # Hugo Decrypte
        self.base_url = "https://www.googleapis.com/youtube/v3"
        self.output_dir = Path("data/raw/external_apis")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        if not self.api_key:
            logger.error("‚ùå YOUTUBE_API_KEY non d√©finie dans .env")
        else:
            logger.info("üì∫ Collecteur Hugo YouTube initialis√©")
            logger.info(f"üéØ Cha√Æne cible: {self.channel_id}")
    
    def get_channel_info(self):
        """R√©cup√®re les informations de la cha√Æne"""
        logger.info("üìä R√©cup√©ration des informations de la cha√Æne...")
        
        try:
            url = f"{self.base_url}/channels"
            params = {
                'part': 'snippet,statistics',
                'id': self.channel_id,
                'key': self.api_key
            }
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            channels = data.get('items', [])
            
            if channels:
                channel = channels[0]
                info = {
                    'channel_id': self.channel_id,
                    'title': channel['snippet']['title'],
                    'description': channel['snippet']['description'],
                    'subscriber_count': channel['statistics'].get('subscriberCount', '0'),
                    'video_count': channel['statistics'].get('videoCount', '0'),
                    'view_count': channel['statistics'].get('viewCount', '0'),
                    'collected_at': datetime.now().isoformat()
                }
                
                logger.info(f"‚úÖ Cha√Æne trouv√©e: {info['title']}")
                logger.info(f"   üë• Abonn√©s: {info['subscriber_count']}")
                logger.info(f"   üìπ Vid√©os: {info['video_count']}")
                logger.info(f"   üëÄ Vues totales: {info['view_count']}")
                
                return info
            else:
                logger.error("‚ùå Cha√Æne non trouv√©e")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration cha√Æne: {e}")
            return None
    
    def get_recent_videos(self, max_results=10):
        """R√©cup√®re les vid√©os r√©centes de la cha√Æne"""
        logger.info(f"üìπ R√©cup√©ration des {max_results} vid√©os r√©centes...")
        
        try:
            url = f"{self.base_url}/search"
            params = {
                'part': 'snippet',
                'channelId': self.channel_id,
                'type': 'video',
                'order': 'date',
                'maxResults': max_results,
                'key': self.api_key
            }
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            videos = data.get('items', [])
            
            video_details = []
            for video in videos:
                video_id = video['id']['videoId']
                snippet = video['snippet']
                
                # R√©cup√©rer les d√©tails suppl√©mentaires
                details = self.get_video_details(video_id)
                if details:
                    video_info = {
                        'video_id': video_id,
                        'title': snippet['title'],
                        'description': snippet['description'],
                        'published_at': snippet['publishedAt'],
                        'channel_title': snippet['channelTitle'],
                        'view_count': details.get('view_count', 0),
                        'like_count': details.get('like_count', 0),
                        'comment_count': details.get('comment_count', 0),
                        'duration': details.get('duration', ''),
                        'tags': details.get('tags', []),
                        'collected_at': datetime.now().isoformat()
                    }
                    video_details.append(video_info)
                
                # Pause pour √©viter les limites de rate
                time.sleep(0.1)
            
            logger.info(f"‚úÖ {len(video_details)} vid√©os r√©cup√©r√©es")
            return video_details
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration vid√©os: {e}")
            return []
    
    def get_video_details(self, video_id):
        """R√©cup√®re les d√©tails d'une vid√©o sp√©cifique"""
        try:
            url = f"{self.base_url}/videos"
            params = {
                'part': 'statistics,contentDetails',
                'id': video_id,
                'key': self.api_key
            }
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            videos = data.get('items', [])
            
            if videos:
                video = videos[0]
                return {
                    'view_count': int(video['statistics'].get('viewCount', 0)),
                    'like_count': int(video['statistics'].get('likeCount', 0)),
                    'comment_count': int(video['statistics'].get('commentCount', 0)),
                    'duration': video['contentDetails']['duration']
                }
            return None
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur d√©tails vid√©o {video_id}: {e}")
            return None
    
    def anonymize_data(self, data):
        """Anonymise les donn√©es pour RGPD"""
        logger.info("üõ°Ô∏è Anonymisation des donn√©es...")
        
        anonymized_data = []
        for item in data:
            # Supprimer les informations personnelles
            anonymized_item = {
                'content': item.get('title', '') + ' ' + item.get('description', ''),
                'source': 'youtube_hugo',
                'timestamp': item.get('published_at', ''),
                'metadata': {
                    'video_id_hash': hash(item.get('video_id', '')) % (10**8),
                    'view_count': item.get('view_count', 0),
                    'like_count': item.get('like_count', 0),
                    'duration': item.get('duration', '')
                },
                'anonymized': True,
                'collected_at': item.get('collected_at', '')
            }
            anonymized_data.append(anonymized_item)
        
        logger.info(f"‚úÖ {len(anonymized_data)} √©l√©ments anonymis√©s")
        return anonymized_data
    
    def save_data(self, channel_info, videos_data, anonymized_data):
        """Sauvegarde les donn√©es collect√©es"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Sauvegarde des informations de la cha√Æne
        channel_file = self.output_dir / f"hugo_channel_info_{timestamp}.json"
        with open(channel_file, 'w', encoding='utf-8') as f:
            json.dump(channel_info, f, ensure_ascii=False, indent=2)
        
        # Sauvegarde des vid√©os d√©taill√©es
        videos_file = self.output_dir / f"hugo_videos_{timestamp}.json"
        with open(videos_file, 'w', encoding='utf-8') as f:
            json.dump(videos_data, f, ensure_ascii=False, indent=2)
        
        # Sauvegarde des donn√©es anonymis√©es
        anonymized_file = self.output_dir / f"hugo_anonymized_{timestamp}.json"
        with open(anonymized_file, 'w', encoding='utf-8') as f:
            json.dump(anonymized_data, f, ensure_ascii=False, indent=2)
        
        # Sauvegarde CSV pour analyse
        csv_file = self.output_dir / f"hugo_data_{timestamp}.csv"
        df = pd.DataFrame(anonymized_data)
        df.to_csv(csv_file, index=False, encoding='utf-8')
        
        logger.info(f"üíæ Donn√©es sauvegard√©es:")
        logger.info(f"   üìä Cha√Æne: {channel_file}")
        logger.info(f"   üìπ Vid√©os: {videos_file}")
        logger.info(f"   üõ°Ô∏è Anonymis√©es: {anonymized_file}")
        logger.info(f"   üìà CSV: {csv_file}")
        
        return {
            'channel_file': str(channel_file),
            'videos_file': str(videos_file),
            'anonymized_file': str(anonymized_file),
            'csv_file': str(csv_file)
        }
    
    def collect_hugo_data(self, max_videos=10):
        """Collecte compl√®te des donn√©es Hugo"""
        logger.info("üöÄ D√âBUT DE LA COLLECTE HUGO DECRYPTE")
        logger.info("=" * 60)
        
        if not self.api_key:
            logger.error("‚ùå Cl√© API YouTube manquante")
            return False
        
        # 1. Informations de la cha√Æne
        channel_info = self.get_channel_info()
        if not channel_info:
            return False
        
        # 2. Vid√©os r√©centes
        videos_data = self.get_recent_videos(max_videos)
        if not videos_data:
            logger.warning("‚ö†Ô∏è Aucune vid√©o r√©cup√©r√©e")
            return False
        
        # 3. Anonymisation
        anonymized_data = self.anonymize_data(videos_data)
        
        # 4. Sauvegarde
        files = self.save_data(channel_info, videos_data, anonymized_data)
        
        # 5. R√©sum√©
        logger.info("\n" + "=" * 60)
        logger.info("üìä R√âSUM√â DE LA COLLECTE")
        logger.info("=" * 60)
        logger.info(f"üì∫ Cha√Æne: {channel_info['title']}")
        logger.info(f"üë• Abonn√©s: {channel_info['subscriber_count']}")
        logger.info(f"üìπ Vid√©os collect√©es: {len(videos_data)}")
        logger.info(f"üõ°Ô∏è Donn√©es anonymis√©es: {len(anonymized_data)}")
        logger.info("=" * 60)
        
        return True

def main():
    """Fonction principale"""
    logger.info("üì∫ COLLECTE HUGO DECRYPTE - SEMANTIC PULSE X")
    
    collector = HugoYouTubeCollector()
    
    try:
        success = collector.collect_hugo_data(max_videos=15)
        if success:
            logger.info("üéâ Collecte Hugo termin√©e avec succ√®s!")
            return True
        else:
            logger.error("‚ùå √âchec de la collecte Hugo")
            return False
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la collecte: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)




