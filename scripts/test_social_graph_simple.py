#!/usr/bin/env python3
"""
Test autonome du Graphe Social des √âmotions - Semantic Pulse X
Version simplifi√©e sans d√©pendances externes
"""

import os
import json
import logging
from datetime import datetime
from collections import defaultdict, Counter
import numpy as np

# Configuration du logger
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SimpleSocialGraph:
    """Version simplifi√©e du graphe social des √©motions."""
    
    def __init__(self):
        self.emotions = {}
        self.themes = {}
        self.relations = defaultdict(list)
        self.clusters = {}
        
        logger.info("üîó Graphe Social Simple initialis√©")
    
    def add_emotion_data(self, emotion_data):
        """Ajoute des donn√©es √©motionnelles."""
        logger.info(f"üìä Ajout de {len(emotion_data)} √©l√©ments √©motionnels")
        
        for item in emotion_data:
            emotion = item.get('emotion', 'unknown')
            theme = item.get('theme', 'general')
            content = item.get('content', '')
            source = item.get('source', 'unknown')
            
            # Ajouter l'√©motion
            if emotion not in self.emotions:
                self.emotions[emotion] = {
                    'frequency': 0,
                    'themes': set(),
                    'sources': set(),
                    'content_samples': []
                }
            
            self.emotions[emotion]['frequency'] += 1
            self.emotions[emotion]['themes'].add(theme)
            self.emotions[emotion]['sources'].add(source)
            self.emotions[emotion]['content_samples'].append(content[:50])
            
            # Ajouter le th√®me
            if theme not in self.themes:
                self.themes[theme] = {
                    'frequency': 0,
                    'emotions': set(),
                    'sources': set()
                }
            
            self.themes[theme]['frequency'] += 1
            self.themes[theme]['emotions'].add(emotion)
            self.themes[theme]['sources'].add(source)
            
            # Cr√©er la relation
            self.relations[f"{emotion}-{theme}"].append({
                'content': content,
                'source': source,
                'timestamp': item.get('timestamp', datetime.now().isoformat())
            })
        
        logger.info(f"‚úÖ Graphe mis √† jour: {len(self.emotions)} √©motions, {len(self.themes)} th√®mes")
    
    def perform_clustering(self, n_clusters=3):
        """Effectue le clustering des √©motions."""
        logger.info(f"üîç Clustering des √©motions en {n_clusters} groupes")
        
        # Clustering simple bas√© sur les th√®mes partag√©s
        emotion_list = list(self.emotions.keys())
        clusters = defaultdict(list)
        
        # Algorithme de clustering simple
        for i, emotion in enumerate(emotion_list):
            cluster_id = i % n_clusters
            clusters[f"cluster_{cluster_id}"].append(emotion)
        
        # Calculer les m√©triques des clusters
        cluster_metrics = {}
        for cluster_name, emotions in clusters.items():
            cluster_metrics[cluster_name] = {
                'size': len(emotions),
                'emotions': emotions,
                'avg_frequency': np.mean([self.emotions[e]['frequency'] for e in emotions]),
                'themes': set()
            }
            
            # Collecter tous les th√®mes du cluster
            for emotion in emotions:
                cluster_metrics[cluster_name]['themes'].update(self.emotions[emotion]['themes'])
        
        self.clusters = dict(clusters)
        
        logger.info(f"‚úÖ Clustering termin√©: {len(clusters)} clusters cr√©√©s")
        for cluster_name, metrics in cluster_metrics.items():
            logger.info(f"   {cluster_name}: {metrics['size']} √©motions, {len(metrics['themes'])} th√®mes")
        
        return cluster_metrics
    
    def analyze_influences(self):
        """Analyse les influences entre √©motions."""
        logger.info("üìà Analyse des influences √©motionnelles")
        
        influences = {}
        emotion_list = list(self.emotions.keys())
        
        for i, emotion1 in enumerate(emotion_list):
            for j, emotion2 in enumerate(emotion_list):
                if i != j:
                    themes1 = self.emotions[emotion1]['themes']
                    themes2 = self.emotions[emotion2]['themes']
                    
                    if themes1 and themes2:
                        shared_themes = themes1.intersection(themes2)
                        influence = len(shared_themes) / len(themes1) if themes1 else 0
                        
                        if influence > 0:
                            influences[f"{emotion1}_to_{emotion2}"] = {
                                'influence_score': influence,
                                'shared_themes': list(shared_themes),
                                'source_frequency': self.emotions[emotion1]['frequency'],
                                'target_frequency': self.emotions[emotion2]['frequency']
                            }
        
        # Identifier les √©motions les plus influentes
        influence_scores = defaultdict(float)
        for relation, data in influences.items():
            emotion = relation.split('_to_')[0]
            influence_scores[emotion] += data['influence_score']
        
        most_influential = sorted(influence_scores.items(), key=lambda x: x[1], reverse=True)
        
        logger.info(f"‚úÖ Analyse termin√©e: {len(influences)} relations d'influence")
        logger.info("üèÜ Top 3 √©motions les plus influentes:")
        for i, (emotion, score) in enumerate(most_influential[:3]):
            logger.info(f"   {i+1}. {emotion}: score {score:.3f}")
        
        return {
            'influence_relations': influences,
            'most_influential': most_influential[:10]
        }
    
    def generate_theme_mapping(self):
        """G√©n√®re le mapping des th√®mes vers les √©motions."""
        logger.info("üó∫Ô∏è G√©n√©ration du mapping th√®me-√©motions")
        
        theme_mapping = {}
        for theme, data in self.themes.items():
            theme_mapping[theme] = {
                'emotions': list(data['emotions']),
                'emotion_count': len(data['emotions']),
                'frequency': data['frequency'],
                'emotion_distribution': {}
            }
            
            # Calculer la distribution des √©motions pour ce th√®me
            for emotion in data['emotions']:
                emotion_freq = self.emotions[emotion]['frequency']
                theme_mapping[theme]['emotion_distribution'][emotion] = emotion_freq
        
        logger.info(f"‚úÖ Mapping g√©n√©r√© pour {len(theme_mapping)} th√®mes")
        for theme, data in theme_mapping.items():
            logger.info(f"   {theme}: {data['emotion_count']} √©motions, fr√©quence {data['frequency']}")
        
        return theme_mapping
    
    def get_statistics(self):
        """Calcule les statistiques du graphe."""
        logger.info("üìä Calcul des statistiques du graphe")
        
        stats = {
            'basic_metrics': {
                'total_emotions': len(self.emotions),
                'total_themes': len(self.themes),
                'total_relations': len(self.relations),
                'avg_emotion_frequency': np.mean([e['frequency'] for e in self.emotions.values()]),
                'avg_theme_frequency': np.mean([t['frequency'] for t in self.themes.values()])
            },
            'clustering_metrics': {
                'total_clusters': len(self.clusters),
                'cluster_sizes': [len(emotions) for emotions in self.clusters.values()],
                'average_cluster_size': np.mean([len(emotions) for emotions in self.clusters.values()]) if self.clusters else 0
            }
        }
        
        logger.info("‚úÖ Statistiques calcul√©es")
        logger.info(f"   üìä √âmotions: {stats['basic_metrics']['total_emotions']}")
        logger.info(f"   üéØ Th√®mes: {stats['basic_metrics']['total_themes']}")
        logger.info(f"   üîó Relations: {stats['basic_metrics']['total_relations']}")
        
        return stats
    
    def export_data(self, output_path="data/processed/social_graph_simple.json"):
        """Exporte les donn√©es du graphe."""
        logger.info("üíæ Export des donn√©es du graphe")
        
        # Convertir les sets en listes pour la s√©rialisation JSON
        emotions_data = {}
        for emotion, data in self.emotions.items():
            emotions_data[emotion] = {
                'frequency': data['frequency'],
                'themes': list(data['themes']),
                'sources': list(data['sources']),
                'content_samples': data['content_samples']
            }
        
        themes_data = {}
        for theme, data in self.themes.items():
            themes_data[theme] = {
                'frequency': data['frequency'],
                'emotions': list(data['emotions']),
                'sources': list(data['sources'])
            }
        
        graph_data = {
            'metadata': {
                'timestamp': datetime.now().isoformat(),
                'total_emotions': len(self.emotions),
                'total_themes': len(self.themes),
                'total_relations': len(self.relations)
            },
            'emotions': emotions_data,
            'themes': themes_data,
            'relations': dict(self.relations),
            'clusters': self.clusters
        }
        
        # Sauvegarder
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(graph_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ Donn√©es export√©es: {output_path}")
        return graph_data

def create_sample_data():
    """Cr√©e des donn√©es d'exemple."""
    return [
        {'emotion': 'joie', 'content': 'Excellente nouvelle aujourd\'hui!', 'theme': 'actualit√©', 'source': 'twitter', 'timestamp': '2025-01-01T10:00:00Z'},
        {'emotion': 'tristesse', 'content': 'Tr√®s triste de cette annonce...', 'theme': 'actualit√©', 'source': 'twitter', 'timestamp': '2025-01-01T11:00:00Z'},
        {'emotion': 'col√®re', 'content': 'Je suis en col√®re contre cette d√©cision', 'theme': 'politique', 'source': 'youtube', 'timestamp': '2025-01-01T12:00:00Z'},
        {'emotion': 'peur', 'content': 'J\'ai peur des cons√©quences', 'theme': 'politique', 'source': 'youtube', 'timestamp': '2025-01-01T13:00:00Z'},
        {'emotion': 'surprise', 'content': 'Quelle surprise cette r√©v√©lation!', 'theme': 'actualit√©', 'source': 'twitter', 'timestamp': '2025-01-01T14:00:00Z'},
        {'emotion': 'd√©go√ªt', 'content': 'C\'est d√©go√ªtant ce qui se passe', 'theme': 'soci√©t√©', 'source': 'twitter', 'timestamp': '2025-01-01T15:00:00Z'},
        {'emotion': 'joie', 'content': 'Enfin une bonne nouvelle!', 'theme': 'soci√©t√©', 'source': 'youtube', 'timestamp': '2025-01-01T16:00:00Z'},
        {'emotion': 'tristesse', 'content': 'C\'est vraiment triste', 'theme': 'soci√©t√©', 'source': 'twitter', 'timestamp': '2025-01-01T17:00:00Z'},
        {'emotion': 'col√®re', 'content': 'Cette injustice me met en col√®re', 'theme': 'actualit√©', 'source': 'youtube', 'timestamp': '2025-01-01T18:00:00Z'},
        {'emotion': 'peur', 'content': 'L\'avenir me fait peur', 'theme': 'politique', 'source': 'twitter', 'timestamp': '2025-01-01T19:00:00Z'}
    ]

def main():
    """Fonction principale de test."""
    logger.info("üöÄ TEST GRAPHE SOCIAL DES √âMOTIONS - VERSION SIMPLE")
    logger.info("=" * 70)
    
    try:
        # Cr√©er le graphe
        social_graph = SimpleSocialGraph()
        
        # Ajouter des donn√©es d'exemple
        sample_data = create_sample_data()
        social_graph.add_emotion_data(sample_data)
        
        # Effectuer le clustering
        cluster_metrics = social_graph.perform_clustering(n_clusters=3)
        
        # Analyser les influences
        influence_analysis = social_graph.analyze_influences()
        
        # G√©n√©rer le mapping des th√®mes
        theme_mapping = social_graph.generate_theme_mapping()
        
        # Calculer les statistiques
        stats = social_graph.get_statistics()
        
        # Exporter les donn√©es
        graph_data = social_graph.export_data()
        
        # R√©sum√© final
        logger.info("\n" + "=" * 70)
        logger.info("üéâ TEST R√âUSSI!")
        logger.info("=" * 70)
        logger.info(f"‚úÖ Graphe cr√©√©: {len(social_graph.emotions)} √©motions, {len(social_graph.themes)} th√®mes")
        logger.info(f"‚úÖ Clusters: {len(cluster_metrics)}")
        logger.info(f"‚úÖ Relations d'influence: {len(influence_analysis['influence_relations'])}")
        logger.info(f"‚úÖ Th√®mes mapp√©s: {len(theme_mapping)}")
        logger.info("=" * 70)
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du test: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
