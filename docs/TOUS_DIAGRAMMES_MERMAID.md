# üéØ TOUS LES DIAGRAMMES MERMAID - Semantic Pulse X

## 1Ô∏è‚É£ DIAGRAMME MCD (Mod√®le Conceptuel de Donn√©es)

```mermaid
erDiagram
    DIM_PAYS {
        integer id PK
        varchar nom
        varchar code_iso
    }
    
    DIM_DOMAINE {
        integer id PK
        varchar nom
        text description
    }
    
    DIM_HUMEUR {
        integer id PK
        varchar nom
        varchar couleur
        text description
    }
    
    SOURCES {
        integer id PK
        varchar nom "VARCHAR(100)"
        varchar type "VARCHAR(20)"
        varchar url_base "VARCHAR(500)"
        boolean actif
        datetime created_at
    }
    
    CONTENUS {
        integer id PK
        integer source_id FK
        integer pays_id FK
        integer domaine_id FK
        varchar url "VARCHAR(1000)"
        text titre
        text resume
        text texte
        datetime publication_date
        varchar auteur "VARCHAR(200)"
        varchar langue "VARCHAR(5)"
        datetime collected_at
        varchar sentiment "VARCHAR(30)"
        float confidence
        text themes
        varchar source_type "VARCHAR(50)"
    }
    
    REACTIONS {
        integer id PK
        integer contenu_id FK
        integer humeur_id FK
        float score
        float confidence
        datetime created_at
    }
    
    %% Relations avec cardinalit√©s exactes
    DIM_PAYS ||--o{ CONTENUS : "localise"
    DIM_DOMAINE ||--o{ CONTENUS : "cat√©gorise"
    DIM_HUMEUR ||--o{ REACTIONS : "d√©finit"
    SOURCES ||--o{ CONTENUS : "produit"
    CONTENUS ||--o{ REACTIONS : "g√©n√®re"
```

## 2Ô∏è‚É£ DIAGRAMME DES 5 SOURCES ‚Üí 6√®me BDD

```mermaid
graph TD
    A[Kaggle 50%<br/>Fichier plat CSV<br/>3,333 tweets] --> E[Pipeline ETL]
    B[Kaggle 50%<br/>Base simple SQLite<br/>3,333 tweets] --> E
    C[GDELT GKG<br/>Big Data<br/>1,283 √©v√©nements] --> E
    D[YouTube + NewsAPI<br/>APIs externes<br/>180 vid√©os + articles] --> E
    F[Yahoo + Franceinfo<br/>Web Scraping<br/>Articles temps r√©el] --> E
    
    E --> G[aggregate_sources.py]
    G --> H[load_aggregated_to_db.py]
    H --> I[semantic_pulse.db<br/>Base MERISE finale<br/>535 contenus, 487 sources]
    
    I --> J[DIM_PAYS: 1]
    I --> K[DIM_DOMAINE: 2]
    I --> L[DIM_HUMEUR: 3]
    I --> M[SOURCES: 487]
    I --> N[CONTENUS: 535]
    I --> O[REACTIONS: 0]
    
    style A fill:#e1f5fe
    style B fill:#e8f5e8
    style C fill:#fff3e0
    style D fill:#fce4ec
    style F fill:#f3e5f5
    style I fill:#e0f2f1
```

## 3Ô∏è‚É£ ARCHITECTURE 3 COUCHES

```mermaid
graph TB
    subgraph "Couche Application"
        A[Streamlit Frontend<br/>app/frontend/streamlit_app.py]
        B[FastAPI Backend<br/>app/backend/main.py]
    end
    
    subgraph "Couche Donn√©es MERISE"
        C[semantic_pulse.db<br/>Base principale]
        D[kaggle_tweets.db<br/>Base Kaggle]
        E[Parquet Files<br/>Big Data]
        F[MinIO<br/>Data Lake]
    end
    
    subgraph "Couche Sources"
        G[Kaggle CSV<br/>1000 tweets]
        H[YouTube API<br/>180 vid√©os]
        I[Web Scraping<br/>Yahoo/Franceinfo]
        J[GDELT GKG<br/>Big Data]
        K[NewsAPI<br/>Articles]
    end
    
    subgraph "Couche IA"
        L[Emotion Classifier<br/>HuggingFace]
        M[Topic Clustering<br/>BERTopic]
        N[Embeddings<br/>SentenceTransformer]
        O[Ollama<br/>LLM Local]
    end
    
    A --> B
    B --> C
    B --> D
    B --> E
    B --> F
    
    G --> B
    H --> B
    I --> B
    J --> B
    K --> B
    
    B --> L
    B --> M
    B --> N
    B --> O
    
    style C fill:#e3f2fd
    style D fill:#e8f5e8
    style E fill:#fff3e0
    style F fill:#fce4ec
```

## 4Ô∏è‚É£ PIPELINE ETL COMPLET

```mermaid
flowchart TD
    subgraph "EXTRACTION"
        A1[Kaggle CSV<br/>1000 tweets]
        A2[YouTube API<br/>180 vid√©os]
        A3[Web Scraping<br/>Yahoo/Franceinfo]
        A4[GDELT GKG<br/>Big Data]
        A5[NewsAPI<br/>Articles]
    end
    
    subgraph "NETTOYAGE"
        B1[aggregate_sources.py<br/>D√©duplication]
        B2[Anonymisation RGPD<br/>PII Removal]
        B3[Normalisation<br/>Standardisation]
        B4[Validation<br/>Qualit√© donn√©es]
    end
    
    subgraph "TRANSFORMATION"
        C1[Conversion types<br/>Datetime/String]
        C2[Enrichissement<br/>Sentiment/Confidence]
        C3[Mapping dimensions<br/>Pays/Domaine/Humeur]
        C4[G√©n√©ration JSON<br/>Format standard]
    end
    
    subgraph "CHARGEMENT"
        D1[load_aggregated_to_db.py<br/>SQLite MERISE]
        D2[load_kaggle_to_db.py<br/>SQLite Kaggle]
        D3[Parquet Files<br/>Big Data]
        D4[MinIO Upload<br/>Data Lake]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B1
    A4 --> B1
    A5 --> B1
    
    B1 --> B2
    B2 --> B3
    B3 --> B4
    
    B4 --> C1
    C1 --> C2
    C2 --> C3
    C3 --> C4
    
    C4 --> D1
    C4 --> D2
    C4 --> D3
    C4 --> D4
    
    style B1 fill:#ffebee
    style C1 fill:#e8f5e8
    style D1 fill:#e3f2fd
    style D2 fill:#e3f2fd
```

## 5Ô∏è‚É£ CONFORMIT√â RGPD

```mermaid
graph LR
    subgraph "DONN√âES BRUTES"
        A[Texte original<br/>YouTube/Web]
        B[Identifiants<br/>URLs/IDs]
        C[G√©olocalisation<br/>Pays exact]
        D[Dates pr√©cises<br/>Timestamps]
    end
    
    subgraph "ANONYMIZATION"
        E[Texte nettoy√©<br/>PII Removal]
        F[URLs anonymis√©es<br/>Hash SHA-256]
        G[Pays g√©n√©ralis√©<br/>FR/EN/etc]
        H[Dates anonymis√©es<br/>P√©riodes]
    end
    
    subgraph "PSEUDONYMIZATION"
        I[Hash anonyme<br/>Utilisateurs]
        J[Zone g√©ographique<br/>R√©gions]
        K[Tranche temporelle<br/>P√©riodes]
        L[M√©tadonn√©es<br/>S√©curis√©es]
    end
    
    subgraph "TRACABILIT√â"
        M[Logs ingestion<br/>sources table]
        N[Audit trail<br/>collected_at]
        O[Droits utilisateurs<br/>RGPD compliant]
        P[Suppression<br/>Right to forget]
    end
    
    A --> E
    B --> F
    C --> G
    D --> H
    
    E --> I
    F --> I
    G --> J
    H --> K
    
    I --> M
    J --> N
    K --> O
    L --> P
    
    style E fill:#e8f5e8
    style F fill:#e8f5e8
    style I fill:#e3f2fd
    style M fill:#fff3e0
```

## 6Ô∏è‚É£ MONITORING & M√âTRIQUES

```mermaid
graph TB
    subgraph "M√âTRIQUES"
        A[Prometheus<br/>Port 9090]
        B[Grafana Dashboard<br/>Port 3000]
    end
    
    subgraph "INDICATEURS"
        C[Qualit√© donn√©es<br/>535 contenus]
        D[Performance ETL<br/>5 sources]
        E[Conformit√© RGPD<br/>Anonymisation]
        F[Disponibilit√© services<br/>Docker Compose]
    end
    
    subgraph "ALERTES"
        G[Seuils qualit√©<br/>Confidence < 0.5]
        H[D√©lais ETL<br/>Timeout > 30s]
        I[Erreurs RGPD<br/>PII d√©tect√©]
        J[Pannes services<br/>Ports ferm√©s]
    end
    
    A --> C
    A --> D
    A --> E
    A --> F
    
    C --> G
    D --> H
    E --> I
    F --> J
    
    B --> A
    
    style A fill:#e3f2fd
    style B fill:#e8f5e8
    style G fill:#ffebee
    style H fill:#ffebee
```

## 7Ô∏è‚É£ SURVEILLANCE D√âRIVE MOD√àLES

```mermaid
graph TD
    subgraph "DONN√âES HISTORIQUES"
        A[Dataset de r√©f√©rence<br/>Kaggle Sentiment140]
        B[Mod√®les entra√Æn√©s<br/>HuggingFace]
        C[M√©triques de base<br/>PSI/KS Test]
    end
    
    subgraph "D√âRIVE D√âTECT√âE"
        D[Data Drift<br/>Distribution chang√©e]
        E[Prediction Drift<br/>Pr√©dictions d√©cal√©es]
        F[Performance Drift<br/>Accuracy d√©grad√©e]
    end
    
    subgraph "ALERTES AUTOMATIQUES"
        G[Email/Slack<br/>Seuil d√©pass√©]
        H[Dashboard Grafana<br/>M√©triques temps r√©el]
        I[Logs Prometheus<br/>Historique d√©rive]
    end
    
    subgraph "ACTIONS CORRECTIVES"
        J[Re-entra√Ænement<br/>Mod√®le mis √† jour]
        K[Validation crois√©e<br/>Tests qualit√©]
        L[D√©ploiement<br/>Nouvelle version]
    end
    
    A --> D
    B --> E
    C --> F
    
    D --> G
    E --> H
    F --> I
    
    G --> J
    H --> K
    I --> L
    
    style D fill:#ffebee
    style E fill:#ffebee
    style F fill:#ffebee
    style J fill:#e8f5e8
    style K fill:#e8f5e8
    style L fill:#e8f5e8
```

---

## üéØ **INSTRUCTIONS POUR V√âRIFICATION**

### **√âtapes de v√©rification :**

1. **Copiez chaque diagramme** (code entre ```mermaid et ```)
2. **Allez sur** [Mermaid Live Editor](https://mermaid.live/)
3. **Collez le code** dans l'√©diteur
4. **V√©rifiez le rendu** :
   - ‚úÖ Cardinalit√©s correctes
   - ‚úÖ Couleurs coh√©rentes  
   - ‚úÖ Labels lisibles
   - ‚úÖ Relations logiques
   - ‚úÖ Pas d'erreurs de syntaxe

### **Points de contr√¥le :**

- **MCD** : 6 tables avec PK/FK et cardinalit√©s exactes
- **Sources** : 5 sources distinctes ‚Üí base MERISE
- **Architecture** : 3 couches bien s√©par√©es
- **ETL** : 4 √©tapes (Extract/Clean/Transform/Load)
- **RGPD** : 4 niveaux de protection
- **Monitoring** : M√©triques + Alertes + Actions

**Tous les diagrammes sont bas√©s sur la structure R√âELLE de semantic_pulse.db !** üéØ‚úÖ
