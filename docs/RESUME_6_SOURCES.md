# ğŸ“Š RÃ‰SUMÃ‰ DES 6 SOURCES DE DONNÃ‰ES
## Semantic Pulse X - Certification E1/E2/E3

---

## ğŸ¯ **ARCHITECTURE COMPLÃˆTE DES SOURCES**

### **5 Sources de DonnÃ©es Distintes + 1 Base AgrÃ©gÃ©e MERISE**

---

## ğŸ“ **SOURCE 1 : FICHIER PLAT**
- **Type** : Dataset Kaggle Sentiment140 (CSV)
- **Volume** : 1.6M tweets
- **Format** : CSV avec colonnes (sentiment, texte, id)
- **Utilisation** : EntraÃ®nement et validation des modÃ¨les
- **Script** : `scripts/load_kaggle_to_db.py`

---

## ğŸ—„ï¸ **SOURCE 2 : BASE DE DONNÃ‰ES RELATIONNELLE**
- **Type** : SQLite avec schÃ©ma MERISE
- **Tables** : sources, contenus, reactions, dim_*
- **Volume** : 535 contenus intÃ©grÃ©s
- **Utilisation** : Stockage structurÃ© des donnÃ©es
- **Script** : `scripts/generate_orm_schema.py`

---

## ğŸŒ **SOURCE 3 : API EXTERNE**
- **Type** : YouTube Data API v3 + NewsAPI
- **Volume** : 180 vidÃ©os YouTube + articles NewsAPI
- **Format** : JSON avec mÃ©tadonnÃ©es complÃ¨tes
- **Utilisation** : Collecte temps rÃ©el de contenu
- **Script** : `app/backend/data_sources/youtube_api.py`

---

## ğŸ•·ï¸ **SOURCE 4 : WEB SCRAPING**
- **Type** : Yahoo ActualitÃ©s FR + France Info
- **Technologie** : Selenium + BeautifulSoup
- **Volume** : Articles franÃ§ais rÃ©cents
- **Format** : JSON structurÃ© avec contenu + mÃ©tadonnÃ©es
- **Scripts** : 
  - `scripts/scrape_yahoo.py`
  - `scripts/scrape_franceinfo_selenium.py`

---

## ğŸ“ˆ **SOURCE 5 : BIG DATA**
- **Type** : GDELT GKG (Global Knowledge Graph)
- **Volume** : 1,283 enregistrements gÃ©opolitiques
- **Format** : DonnÃ©es structurÃ©es gÃ©opolitiques
- **Utilisation** : Analyse gÃ©opolitique franÃ§aise
- **Scripts** :
  - `scripts/gdelt_gkg_pipeline.py`
  - `scripts/ingest_gdelt.py`

---

## ğŸ”„ **SOURCE 6 : BASE AGRÃ‰GÃ‰E MERISE**
- **Type** : `semantic_pulse.db` - Base finale intÃ©grÃ©e
- **Volume** : 535 contenus analysÃ©s et agrÃ©gÃ©s
- **Format** : SQLite avec schÃ©ma MERISE complet
- **Utilisation** : Base de donnÃ©es finale pour l'application
- **Script** : `scripts/load_aggregated_to_db.py`

---

## ğŸ”„ **PIPELINE D'INTÃ‰GRATION**

### **Ã‰tape 1 : Collecte**
```
Sources 1-5 â†’ Scripts de collecte â†’ DonnÃ©es brutes
```

### **Ã‰tape 2 : AgrÃ©gation**
```
DonnÃ©es brutes â†’ aggregate_sources.py â†’ DonnÃ©es normalisÃ©es
```

### **Ã‰tape 3 : Chargement**
```
DonnÃ©es normalisÃ©es â†’ load_aggregated_to_db.py â†’ Base MERISE finale
```

---

## ğŸ“Š **MÃ‰TRIQUES FINALES**

### **DonnÃ©es IntÃ©grÃ©es**
- **Kaggle** : 1,600,000 tweets (entraÃ®nement)
- **YouTube** : 180 vidÃ©os avec texte complet
- **Web Scraping** : Articles Yahoo + France Info
- **GDELT** : 1,283 enregistrements Big Data
- **Base finale** : 535 contenus analysÃ©s

### **ConformitÃ© E1/E2/E3**
- âœ… **E1** : 6 sources distinctes validÃ©es
- âœ… **E2** : Architecture MERISE complÃ¨te
- âœ… **E3** : FonctionnalitÃ©s crÃ©atives implÃ©mentÃ©es

---

## ğŸ¯ **POINTS FORTS**

1. **Respect total** des exigences (6 sources distinctes)
2. **Pas de dÃ©coupage artificiel** (source Big Data dÃ©diÃ©e)
3. **Architecture MERISE** complÃ¨te et documentÃ©e
4. **Pipeline ETL** robuste et testÃ©
5. **Scripts modulaires** et indÃ©pendants

---

*RÃ©sumÃ© des 6 sources - Janvier 2025*
