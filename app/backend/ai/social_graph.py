#!/usr/bin/env python3
"""
Graphe Social des √âmotions - Semantic Pulse X
Syst√®me de clustering th√©matique et mapping des relations √©motionnelles
"""

import numpy as np
import pandas as pd
import networkx as nx
from typing import Dict, List, Tuple, Optional
import logging
from datetime import datetime
import json
from collections import defaultdict, Counter
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns

# Configuration du logger
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SocialEmotionGraph:
    """
    Syst√®me de graphe social des √©motions avec clustering th√©matique.
    
    Fonctionnalit√©s :
    - Clustering des √©motions par th√®mes
    - Mapping des relations entre √©motions
    - Analyse des communaut√©s √©motionnelles
    - D√©tection des influences √©motionnelles
    """
    
    def __init__(self):
        self.graph = nx.Graph()
        self.emotion_clusters = {}
        self.theme_mapping = {}
        self.emotion_embeddings = {}
        self.influence_matrix = None
        self.community_structure = {}
        
        logger.info("üîó Graphe Social des √âmotions initialis√©")
    
    def add_emotion_data(self, emotion_data: List[Dict]) -> None:
        """
        Ajoute des donn√©es √©motionnelles au graphe.
        
        Args:
            emotion_data: Liste de dictionnaires contenant les donn√©es √©motionnelles
        """
        logger.info(f"üìä Ajout de {len(emotion_data)} √©l√©ments √©motionnels")
        
        for item in emotion_data:
            emotion = item.get('emotion', 'unknown')
            content = item.get('content', '')
            theme = item.get('theme', 'general')
            timestamp = item.get('timestamp', datetime.now().isoformat())
            source = item.get('source', 'unknown')
            
            # Ajouter le n≈ìud √©motion
            if not self.graph.has_node(emotion):
                self.graph.add_node(emotion, 
                                  emotion_type=emotion,
                                  frequency=0,
                                  themes=set(),
                                  sources=set())
            
            # Mettre √† jour les attributs du n≈ìud
            node_data = self.graph.nodes[emotion]
            node_data['frequency'] += 1
            node_data['themes'].add(theme)
            node_data['sources'].add(source)
            
            # Ajouter les relations avec les th√®mes
            if not self.graph.has_node(theme):
                self.graph.add_node(theme, 
                                  node_type='theme',
                                  emotions=set(),
                                  frequency=0)
            
            theme_data = self.graph.nodes[theme]
            theme_data['emotions'].add(emotion)
            theme_data['frequency'] += 1
            
            # Cr√©er une ar√™te entre √©motion et th√®me
            if not self.graph.has_edge(emotion, theme):
                self.graph.add_edge(emotion, theme, 
                                  weight=0,
                                  interactions=[])
            
            edge_data = self.graph.edges[emotion, theme]
            edge_data['weight'] += 1
            edge_data['interactions'].append({
                'timestamp': timestamp,
                'content': content[:100],  # Limiter la taille
                'source': source
            })
        
        logger.info(f"‚úÖ Graphe mis √† jour: {self.graph.number_of_nodes()} n≈ìuds, {self.graph.number_of_edges()} ar√™tes")
    
    def perform_emotion_clustering(self, n_clusters: int = 5) -> Dict:
        """
        Effectue le clustering des √©motions par similarit√© s√©mantique.
        
        Args:
            n_clusters: Nombre de clusters souhait√©s
            
        Returns:
            Dictionnaire contenant les clusters et leurs m√©triques
        """
        logger.info(f"üîç Clustering des √©motions en {n_clusters} groupes")
        
        # Extraire les √©motions et leurs embeddings
        emotions = list(self.graph.nodes())
        emotion_nodes = [node for node in emotions if self.graph.nodes[node].get('emotion_type')]
        
        if len(emotion_nodes) < n_clusters:
            logger.warning(f"‚ö†Ô∏è Pas assez d'√©motions pour {n_clusters} clusters")
            n_clusters = len(emotion_nodes)
        
        # Cr√©er une matrice de similarit√© bas√©e sur les th√®mes partag√©s
        similarity_matrix = np.zeros((len(emotion_nodes), len(emotion_nodes)))
        
        for i, emotion1 in enumerate(emotion_nodes):
            for j, emotion2 in enumerate(emotion_nodes):
                if i != j:
                    # Calculer la similarit√© bas√©e sur les th√®mes partag√©s
                    themes1 = self.graph.nodes[emotion1].get('themes', set())
                    themes2 = self.graph.nodes[emotion2].get('themes', set())
                    
                    if themes1 and themes2:
                        intersection = len(themes1.intersection(themes2))
                        union = len(themes1.union(themes2))
                        similarity = intersection / union if union > 0 else 0
                        similarity_matrix[i][j] = similarity
        
        # Clustering avec KMeans
        if n_clusters > 1:
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            cluster_labels = kmeans.fit_predict(similarity_matrix)
        else:
            cluster_labels = [0] * len(emotion_nodes)
        
        # Organiser les r√©sultats
        clusters = defaultdict(list)
        for emotion, label in zip(emotion_nodes, cluster_labels):
            clusters[f"cluster_{label}"].append(emotion)
        
        # Calculer les m√©triques des clusters
        cluster_metrics = {}
        for cluster_name, emotions in clusters.items():
            cluster_metrics[cluster_name] = {
                'size': len(emotions),
                'emotions': emotions,
                'avg_frequency': np.mean([self.graph.nodes[e]['frequency'] for e in emotions]),
                'themes': set()
            }
            
            # Collecter tous les th√®mes du cluster
            for emotion in emotions:
                cluster_metrics[cluster_name]['themes'].update(
                    self.graph.nodes[emotion].get('themes', set())
                )
        
        self.emotion_clusters = dict(clusters)
        
        logger.info(f"‚úÖ Clustering termin√©: {len(clusters)} clusters cr√©√©s")
        for cluster_name, metrics in cluster_metrics.items():
            logger.info(f"   {cluster_name}: {metrics['size']} √©motions, {len(metrics['themes'])} th√®mes")
        
        return cluster_metrics
    
    def detect_emotion_communities(self) -> Dict:
        """
        D√©tecte les communaut√©s d'√©motions dans le graphe.
        
        Returns:
            Dictionnaire des communaut√©s d√©tect√©es
        """
        logger.info("üîç D√©tection des communaut√©s √©motionnelles")
        
        # Utiliser l'algorithme de d√©tection de communaut√©s de NetworkX
        try:
            communities = nx.community.greedy_modularity_communities(self.graph)
        except:
            # Fallback si l'algorithme √©choue
            communities = [list(self.graph.nodes())]
        
        community_structure = {}
        for i, community in enumerate(communities):
            community_name = f"community_{i}"
            community_structure[community_name] = {
                'nodes': list(community),
                'size': len(community),
                'emotions': [node for node in community if self.graph.nodes[node].get('emotion_type')],
                'themes': [node for node in community if self.graph.nodes[node].get('node_type') == 'theme']
            }
        
        self.community_structure = community_structure
        
        logger.info(f"‚úÖ {len(communities)} communaut√©s d√©tect√©es")
        for name, structure in community_structure.items():
            logger.info(f"   {name}: {structure['size']} n≈ìuds ({len(structure['emotions'])} √©motions, {len(structure['themes'])} th√®mes)")
        
        return community_structure
    
    def analyze_emotion_influence(self) -> Dict:
        """
        Analyse l'influence entre les √©motions.
        
        Returns:
            Dictionnaire des influences √©motionnelles
        """
        logger.info("üìä Analyse des influences √©motionnelles")
        
        # Calculer la matrice d'influence bas√©e sur les poids des ar√™tes
        emotion_nodes = [node for node in self.graph.nodes() 
                        if self.graph.nodes[node].get('emotion_type')]
        
        influence_matrix = np.zeros((len(emotion_nodes), len(emotion_nodes)))
        influence_dict = {}
        
        for i, emotion1 in enumerate(emotion_nodes):
            for j, emotion2 in enumerate(emotion_nodes):
                if i != j:
                    # Calculer l'influence bas√©e sur les th√®mes partag√©s
                    themes1 = self.graph.nodes[emotion1].get('themes', set())
                    themes2 = self.graph.nodes[emotion2].get('themes', set())
                    
                    if themes1 and themes2:
                        shared_themes = themes1.intersection(themes2)
                        influence = len(shared_themes) / len(themes1) if themes1 else 0
                        influence_matrix[i][j] = influence
                        
                        if influence > 0:
                            influence_dict[f"{emotion1}_to_{emotion2}"] = {
                                'influence_score': influence,
                                'shared_themes': list(shared_themes),
                                'source_frequency': self.graph.nodes[emotion1]['frequency'],
                                'target_frequency': self.graph.nodes[emotion2]['frequency']
                            }
        
        self.influence_matrix = influence_matrix
        
        # Identifier les √©motions les plus influentes
        influence_scores = np.sum(influence_matrix, axis=1)
        most_influential = []
        
        for i, score in enumerate(influence_scores):
            if score > 0:
                most_influential.append({
                    'emotion': emotion_nodes[i],
                    'influence_score': score,
                    'frequency': self.graph.nodes[emotion_nodes[i]]['frequency']
                })
        
        most_influential.sort(key=lambda x: x['influence_score'], reverse=True)
        
        logger.info(f"‚úÖ Analyse termin√©e: {len(influence_dict)} relations d'influence")
        logger.info("üèÜ Top 3 √©motions les plus influentes:")
        for i, emotion_data in enumerate(most_influential[:3]):
            logger.info(f"   {i+1}. {emotion_data['emotion']}: score {emotion_data['influence_score']:.3f}")
        
        return {
            'influence_matrix': influence_matrix.tolist(),
            'influence_relations': influence_dict,
            'most_influential': most_influential[:10],
            'emotion_nodes': emotion_nodes
        }
    
    def generate_theme_mapping(self) -> Dict:
        """
        G√©n√®re le mapping des th√®mes vers les √©motions.
        
        Returns:
            Dictionnaire du mapping th√®me-√©motions
        """
        logger.info("üó∫Ô∏è G√©n√©ration du mapping th√®me-√©motions")
        
        theme_mapping = {}
        
        for node in self.graph.nodes():
            if self.graph.nodes[node].get('node_type') == 'theme':
                emotions = self.graph.nodes[node].get('emotions', set())
                theme_mapping[node] = {
                    'emotions': list(emotions),
                    'emotion_count': len(emotions),
                    'frequency': self.graph.nodes[node]['frequency'],
                    'emotion_distribution': {}
                }
                
                # Calculer la distribution des √©motions pour ce th√®me
                for emotion in emotions:
                    emotion_freq = self.graph.nodes[emotion]['frequency']
                    theme_mapping[node]['emotion_distribution'][emotion] = emotion_freq
        
        self.theme_mapping = theme_mapping
        
        logger.info(f"‚úÖ Mapping g√©n√©r√© pour {len(theme_mapping)} th√®mes")
        for theme, data in theme_mapping.items():
            logger.info(f"   {theme}: {data['emotion_count']} √©motions, fr√©quence {data['frequency']}")
        
        return theme_mapping
    
    def visualize_graph(self, output_path: str = "data/processed/social_emotion_graph.png") -> None:
        """
        Visualise le graphe social des √©motions.
        
        Args:
            output_path: Chemin de sauvegarde de la visualisation
        """
        logger.info("üìä G√©n√©ration de la visualisation du graphe")
        
        plt.figure(figsize=(15, 10))
        
        # Positionner les n≈ìuds
        pos = nx.spring_layout(self.graph, k=3, iterations=50)
        
        # S√©parer les n≈ìuds par type
        emotion_nodes = [node for node in self.graph.nodes() 
                        if self.graph.nodes[node].get('emotion_type')]
        theme_nodes = [node for node in self.graph.nodes() 
                      if self.graph.nodes[node].get('node_type') == 'theme']
        
        # Dessiner le graphe
        nx.draw_networkx_nodes(self.graph, pos, 
                              nodelist=emotion_nodes,
                              node_color='lightblue',
                              node_size=500,
                              alpha=0.7,
                              label='√âmotions')
        
        nx.draw_networkx_nodes(self.graph, pos,
                              nodelist=theme_nodes,
                              node_color='lightcoral',
                              node_size=300,
                              alpha=0.7,
                              label='Th√®mes')
        
        # Dessiner les ar√™tes
        nx.draw_networkx_edges(self.graph, pos,
                              edge_color='gray',
                              alpha=0.5,
                              width=1)
        
        # Ajouter les labels
        nx.draw_networkx_labels(self.graph, pos,
                               font_size=8,
                               font_weight='bold')
        
        plt.title("Graphe Social des √âmotions - Semantic Pulse X", fontsize=16, fontweight='bold')
        plt.legend()
        plt.axis('off')
        
        # Sauvegarder
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"‚úÖ Visualisation sauvegard√©e: {output_path}")
    
    def export_graph_data(self, output_path: str = "data/processed/social_graph_data.json") -> Dict:
        """
        Exporte les donn√©es du graphe social.
        
        Args:
            output_path: Chemin de sauvegarde des donn√©es
            
        Returns:
            Dictionnaire contenant toutes les donn√©es du graphe
        """
        logger.info("üíæ Export des donn√©es du graphe social")
        
        graph_data = {
            'metadata': {
                'timestamp': datetime.now().isoformat(),
                'total_nodes': self.graph.number_of_nodes(),
                'total_edges': self.graph.number_of_edges(),
                'emotion_nodes': len([n for n in self.graph.nodes() if self.graph.nodes[n].get('emotion_type')]),
                'theme_nodes': len([n for n in self.graph.nodes() if self.graph.nodes[n].get('node_type') == 'theme'])
            },
            'nodes': dict(self.graph.nodes(data=True)),
            'edges': list(self.graph.edges(data=True)),
            'emotion_clusters': self.emotion_clusters,
            'community_structure': self.community_structure,
            'theme_mapping': self.theme_mapping,
            'influence_analysis': self.analyze_emotion_influence() if self.influence_matrix is None else {
                'influence_matrix': self.influence_matrix.tolist(),
                'most_influential': []
            }
        }
        
        # Convertir les sets en listes pour la s√©rialisation JSON
        for node_data in graph_data['nodes'].values():
            if 'themes' in node_data:
                node_data['themes'] = list(node_data['themes'])
            if 'sources' in node_data:
                node_data['sources'] = list(node_data['sources'])
            if 'emotions' in node_data:
                node_data['emotions'] = list(node_data['emotions'])
        
        # Sauvegarder
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(graph_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ Donn√©es export√©es: {output_path}")
        return graph_data
    
    def get_graph_statistics(self) -> Dict:
        """
        Calcule les statistiques du graphe social.
        
        Returns:
            Dictionnaire des statistiques
        """
        logger.info("üìä Calcul des statistiques du graphe")
        
        emotion_nodes = [n for n in self.graph.nodes() if self.graph.nodes[n].get('emotion_type')]
        theme_nodes = [n for n in self.graph.nodes() if self.graph.nodes[n].get('node_type') == 'theme']
        
        stats = {
            'basic_metrics': {
                'total_nodes': self.graph.number_of_nodes(),
                'total_edges': self.graph.number_of_edges(),
                'emotion_nodes': len(emotion_nodes),
                'theme_nodes': len(theme_nodes),
                'density': nx.density(self.graph),
                'average_clustering': nx.average_clustering(self.graph)
            },
            'centrality_measures': {},
            'community_metrics': {},
            'clustering_metrics': {}
        }
        
        if len(emotion_nodes) > 0:
            # Mesures de centralit√©
            degree_centrality = nx.degree_centrality(self.graph)
            betweenness_centrality = nx.betweenness_centrality(self.graph)
            
            stats['centrality_measures'] = {
                'top_degree_centrality': sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5],
                'top_betweenness_centrality': sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]
            }
        
        # M√©triques des communaut√©s
        if self.community_structure:
            stats['community_metrics'] = {
                'total_communities': len(self.community_structure),
                'community_sizes': [structure['size'] for structure in self.community_structure.values()],
                'average_community_size': np.mean([structure['size'] for structure in self.community_structure.values()])
            }
        
        # M√©triques de clustering
        if self.emotion_clusters:
            stats['clustering_metrics'] = {
                'total_clusters': len(self.emotion_clusters),
                'cluster_sizes': [len(emotions) for emotions in self.emotion_clusters.values()],
                'average_cluster_size': np.mean([len(emotions) for emotions in self.emotion_clusters.values()])
            }
        
        logger.info("‚úÖ Statistiques calcul√©es")
        logger.info(f"   üìä Densit√©: {stats['basic_metrics']['density']:.3f}")
        logger.info(f"   üîó Clustering moyen: {stats['basic_metrics']['average_clustering']:.3f}")
        
        return stats

def create_sample_emotion_data() -> List[Dict]:
    """
    Cr√©e des donn√©es √©motionnelles d'exemple pour les tests.
    
    Returns:
        Liste de donn√©es √©motionnelles d'exemple
    """
    sample_data = [
        {'emotion': 'joie', 'content': 'Excellente nouvelle aujourd\'hui!', 'theme': 'actualit√©', 'source': 'twitter', 'timestamp': '2025-01-01T10:00:00Z'},
        {'emotion': 'tristesse', 'content': 'Tr√®s triste de cette annonce...', 'theme': 'actualit√©', 'source': 'twitter', 'timestamp': '2025-01-01T11:00:00Z'},
        {'emotion': 'col√®re', 'content': 'Je suis en col√®re contre cette d√©cision', 'theme': 'politique', 'source': 'youtube', 'timestamp': '2025-01-01T12:00:00Z'},
        {'emotion': 'peur', 'content': 'J\'ai peur des cons√©quences', 'theme': 'politique', 'source': 'youtube', 'timestamp': '2025-01-01T13:00:00Z'},
        {'emotion': 'surprise', 'content': 'Quelle surprise cette r√©v√©lation!', 'theme': 'actualit√©', 'source': 'twitter', 'timestamp': '2025-01-01T14:00:00Z'},
        {'emotion': 'd√©go√ªt', 'content': 'C\'est d√©go√ªtant ce qui se passe', 'theme': 'soci√©t√©', 'source': 'twitter', 'timestamp': '2025-01-01T15:00:00Z'},
        {'emotion': 'joie', 'content': 'Enfin une bonne nouvelle!', 'theme': 'soci√©t√©', 'source': 'youtube', 'timestamp': '2025-01-01T16:00:00Z'},
        {'emotion': 'tristesse', 'content': 'C\'est vraiment triste', 'theme': 'soci√©t√©', 'source': 'twitter', 'timestamp': '2025-01-01T17:00:00Z'},
        {'emotion': 'col√®re', 'content': 'Cette injustice me met en col√®re', 'theme': 'actualit√©', 'source': 'youtube', 'timestamp': '2025-01-01T18:00:00Z'},
        {'emotion': 'peur', 'content': 'L\'avenir me fait peur', 'theme': 'politique', 'source': 'twitter', 'timestamp': '2025-01-01T19:00:00Z'}
    ]
    
    return sample_data

if __name__ == "__main__":
    # Test du syst√®me de graphe social
    logger.info("üöÄ TEST DU GRAPHE SOCIAL DES √âMOTIONS")
    logger.info("=" * 60)
    
    # Cr√©er le graphe
    social_graph = SocialEmotionGraph()
    
    # Ajouter des donn√©es d'exemple
    sample_data = create_sample_emotion_data()
    social_graph.add_emotion_data(sample_data)
    
    # Effectuer le clustering
    cluster_metrics = social_graph.perform_emotion_clustering(n_clusters=3)
    
    # D√©tecter les communaut√©s
    communities = social_graph.detect_emotion_communities()
    
    # Analyser les influences
    influence_analysis = social_graph.analyze_emotion_influence()
    
    # G√©n√©rer le mapping des th√®mes
    theme_mapping = social_graph.generate_theme_mapping()
    
    # Calculer les statistiques
    stats = social_graph.get_graph_statistics()
    
    # Visualiser le graphe
    social_graph.visualize_graph()
    
    # Exporter les donn√©es
    graph_data = social_graph.export_graph_data()
    
    logger.info("\n" + "=" * 60)
    logger.info("‚úÖ TEST TERMIN√â AVEC SUCC√àS")
    logger.info("=" * 60)
    logger.info(f"üìä Graphe cr√©√©: {social_graph.graph.number_of_nodes()} n≈ìuds, {social_graph.graph.number_of_edges()} ar√™tes")
    logger.info(f"üîç Clusters: {len(cluster_metrics)}")
    logger.info(f"üë• Communaut√©s: {len(communities)}")
    logger.info(f"üìà Relations d'influence: {len(influence_analysis['influence_relations'])}")
    logger.info(f"üó∫Ô∏è Th√®mes mapp√©s: {len(theme_mapping)}")
    logger.info("=" * 60)




