# ğŸ§  Semantic Pulse X - Cartographie dynamique des Ã©motions mÃ©diatiques

> **L'IA qui prÃ©dit les vagues Ã©motionnelles mÃ©diatiques avant qu'elles n'arrivent**

## ğŸ¯ Vision

Solution d'intelligence artificielle avancÃ©e capable de cartographier en temps rÃ©el les Ã©motions et thÃ©matiques dominantes dans les mÃ©dias, avec prÃ©diction proactive des tendances Ã©motionnelles.

## ğŸ—ï¸ Architecture

### Structure du Projet
```
Semantic_Pulse_X/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ backend/          # Code backend (API, ETL, IA, etc.)
â”‚   â”‚   â”œâ”€â”€ ai/          # Modules d'intelligence artificielle
â”‚   â”‚   â”œâ”€â”€ api/         # Endpoints REST FastAPI
â”‚   â”‚   â”œâ”€â”€ core/        # Configuration et base de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ data_sources/# Collecte de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ etl/         # Pipeline de traitement
â”‚   â”‚   â”œâ”€â”€ models/      # ModÃ¨les de donnÃ©es
â”‚   â”‚   â””â”€â”€ orchestration/# Prefect et monitoring
â”‚   â””â”€â”€ frontend/        # Interface utilisateur
â”‚       â”œâ”€â”€ streamlit_app.py
â”‚       â””â”€â”€ wordcloud_generator.py
â”œâ”€â”€ scripts/             # Scripts utilitaires
â”œâ”€â”€ docs/               # Documentation complÃ¨te
â”œâ”€â”€ data/               # DonnÃ©es (raw, processed)
â”œâ”€â”€ docker-compose.yml  # Orchestration Docker
â””â”€â”€ requirements.txt    # DÃ©pendances Python
```

### Core Stack
- **FastAPI** - API backend optimisÃ©e
- **Streamlit** - Interface analystes
- **LangChain** - Moteur IA central
- **Pandas + NumPy** - Traitement donnÃ©es haute performance
- **PostgreSQL + SQLite** - Stockage relationnel + Data Lake
- **MinIO** - Stockage objet Big Data
- **Prometheus + Grafana** - Monitoring IA
- **Ollama** - IA locale gratuite

### Sources de donnÃ©es (RGPD-compliant)
1. **Fichiers plats** - Datasets publics anonymisÃ©s (Kaggle, CSV)
2. **Base relationnelle** - PostgreSQL/SQLite avec schÃ©ma MERISE complet
3. **Big Data** - Parquet/Data Lake (GDELT 2.0, donnÃ©es volumÃ©triques)
4. **Scraping web** - Yahoo ActualitÃ©s FR, Franceinfo (Selenium)
5. **API REST** - YouTube Data API v3, NewsAPI

## ğŸ§  Intelligence Artificielle

- **Embeddings** - Sentence Transformers pour vectorisation
- **Emotion AI** - Hugging Face + analyse lexicale franÃ§aise
- **Clustering** - BERTopic pour regroupement thÃ©matique
- **PrÃ©diction** - Prophet/ARIMA/LSTM pour vagues Ã©motionnelles
- **CausalitÃ©** - Granger Causality + attention transformers

## ğŸš€ DÃ©marrage rapide

### Installation locale
```bash
# 1. Cloner le projet
git clone <repository-url>
cd Semantic_Pulse_X

# 2. CrÃ©er l'environnement virtuel
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Configurer les variables d'environnement
cp env.template .env
# Ã‰diter .env avec vos clÃ©s API

# 5. Lancer l'application
python scripts/start_semantic_pulse.bat  # Windows
# ou
streamlit run app/frontend/streamlit_app.py --server.port 8501
```



### DÃ©marrage avec Docker
```bash
# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier le statut
docker-compose ps

# Voir les logs
docker-compose logs -f
```

### DÃ©monstration rapide
```bash
# Web scraping Yahoo ActualitÃ©s
python scripts/scrape_yahoo.py --discover --pays FR --domaine politique

# Web scraping Franceinfo
python scripts/scrape_franceinfo.py --discover --pays FR --domaine politique

# AgrÃ©gation multi-sources avec filtres qualitÃ©
python scripts/aggregate_sources.py --inputs data/raw/scraped/*.json \
    --output-dir data/processed --min-text-len 50 --drop-empty-title

# GÃ©nÃ©ration schÃ©ma ORM complet
python scripts/generate_orm_schema.py --output-dir app/backend/models

# PrÃ©diction Ã©motionnelle (baseline)
python scripts/predict_emotions.py --inputs data/processed/integrated_all_sources_*.json --output-dir data/processed

# Ingestion Big Data GDELT 2.0
python scripts/ingest_gdelt.py --days 7 --output-dir data/processed/bigdata

# Collecter des donnÃ©es YouTube
python scripts/collect_hugo_youtube.py

# Test complet du pipeline
python scripts/test_components_individual.py
```

## ğŸ“Š Monitoring

- **Streamlit** : http://localhost:8501 (Interface principale)
- **API FastAPI** : http://localhost:8000 (Backend API)
- **Documentation API** : http://localhost:8000/docs (Swagger UI)
- **Grafana** : http://localhost:3000 (Monitoring)
- **Prometheus** : http://localhost:9090 (MÃ©triques)
- **Ollama** : http://localhost:11434 (IA locale)

## ğŸ¯ FonctionnalitÃ©s dÃ©montrÃ©es

### âœ… Data Engineering
- **Web scraping rÃ©el** : Yahoo ActualitÃ©s FR, Franceinfo avec Selenium
- **AgrÃ©gation multi-sources** : DÃ©duplication par (URL, titre), gestion valeurs manquantes
- **Filtres qualitÃ©** : Longueur texte minimale, suppression titres vides
- **Nettoyage de donnÃ©es** : Suppression caractÃ¨res spÃ©ciaux, normalisation
- **Anonymisation RGPD** : Hachage SHA-256, suppression donnÃ©es personnelles
- **Pipeline ETL** : Extraction â†’ Nettoyage â†’ Transformation â†’ AgrÃ©gation â†’ Chargement

### âœ… Intelligence Artificielle
- **Classification Ã©motionnelle** : Hugging Face + analyse lexicale franÃ§aise
- **Embeddings sÃ©mantiques** : Sentence Transformers
- **Clustering thÃ©matique** : BERTopic pour regroupement
- **GÃ©nÃ©ration de contenu** : LangChain + Ollama (IA locale gratuite)
- **Analyse temps rÃ©el** : DÃ©tection Ã©motions sur Ã©vÃ©nements actuels

### âœ… Visualisation
- **Nuages de mots** : Visualisation des vagues Ã©motionnelles
- **Dashboards interactifs** : Streamlit responsive
- **Graphiques temporels** : Plotly pour tendances
- **Comparaisons d'Ã©motions** : Analyse comparative
- **MÃ©triques en temps rÃ©el** : Volumes de donnÃ©es par source

### âœ… Architecture
- **API REST** : FastAPI avec documentation Swagger
- **Interface utilisateur** : Streamlit modulaire
- **Base de donnÃ©es** : SQLite/PostgreSQL avec schÃ©ma MERISE
- **Containerisation** : Docker + Docker Compose
- **Monitoring** : Prometheus + Grafana

## ğŸ›¡ï¸ ConformitÃ© RGPD

- **Anonymisation** : Suppression automatique des PII (emails, tÃ©lÃ©phones)
- **Pseudonymisation** : Hachage SHA-256 des identifiants
- **Minimisation** : Seules les donnÃ©es nÃ©cessaires sont collectÃ©es
- **TraÃ§abilitÃ©** : Logs complets de toutes les opÃ©rations
- **Droits utilisateurs** : Effacement, portabilitÃ©, accÃ¨s

## ğŸ“Š ModÃ©lisation MERISE

### MCD (ModÃ¨le Conceptuel de DonnÃ©es)
- **5 entitÃ©s principales** : Programme, Diffusion, Utilisateur, RÃ©action, Source
- **Relations 1:N** entre les entitÃ©s
- **Attributs RGPD-compliant**

### MLD (ModÃ¨le Logique de DonnÃ©es)
- **Tables relationnelles** avec clÃ©s primaires/Ã©trangÃ¨res
- **Logs d'ingestion** pour traÃ§abilitÃ© RGPD
- **Contraintes d'intÃ©gritÃ©**

### MLP (ModÃ¨le Physique de DonnÃ©es)
- **PostgreSQL** : Base principale
- **SQLite** : DÃ©veloppement local
- **Parquet** : Stockage analytique Big Data
- **MinIO** : Data Lake pour fichiers volumineux

## ğŸ“š Documentation ComplÃ¨te

- **ğŸ“‹ RÃ©sumÃ© ExÃ©cutif** : `docs/RESUME_EXECUTIF.md`
- **ğŸ¯ Guide Jury** : `docs/JURY_DEMONSTRATION_GUIDE.md`
- **ğŸ”§ Installation** : `docs/INSTALLATION_GUIDE.md`
- **ğŸ“Š Statut** : `docs/STATUS_APPLICATION.md`
- **ğŸ—ï¸ Architecture** : `docs/ARCHITECTURE.md`
- **ğŸ”’ RGPD** : `docs/RGPD.md`
- **ğŸ—„ï¸ Merise** : `docs/MERISE_MODELING.md`
- **ğŸ“Š SchÃ©ma MERISE** : `docs/SCHEMA_MERISE_COMPLET.md`
- **ğŸ¨ Code Mermaid** : `docs/CODE_MERMAID_MERISE.md`
- **ğŸ“‹ DÃ©coupage Artificiel** : `docs/DECOUPAGE_ARTIFICIEL.md`
- **ğŸ“‹ MÃ©thodologie SCRUM** : `docs/SCRUM_METHODOLOGY.md`

## ğŸ¯ Cas d'usage dÃ©montrÃ©s

### Analyse temps rÃ©el
- **Ã‰vÃ©nement** : "Nouveau gouvernement Lecornu 2"
- **Collecte** : Web scraping sites franÃ§ais
- **Analyse** : DÃ©tection Ã©motions (dÃ©Ã§u, inquiet, sceptique)
- **Confiance** : 90% avec analyse lexicale franÃ§aise
- **RÃ©ponse IA** : SynthÃ¨se en franÃ§ais des rÃ©actions

### Sources de donnÃ©es intÃ©grÃ©es
- **YouTube** : 180 vidÃ©os collectÃ©es
- **Kaggle** : 10,000 tweets analysÃ©s
- **Base de donnÃ©es** : 1,000 enregistrements (schÃ©ma MERISE complet)
- **Big Data** : GDELT 2.0 + 16,984 lignes Parquet
- **Web Scraping** : Yahoo ActualitÃ©s FR + Franceinfo (Selenium)

## ğŸ† Statut du projet

**âœ… PROJET OPÃ‰RATIONNEL ET CONFORME**

- âœ… **Sources de donnÃ©es** : 5 types implÃ©mentÃ©s
- âœ… **Pipeline ETL** : Complet et fonctionnel
- âœ… **MERISE** : MCD/MLD/MLP respectÃ©s
- âœ… **RGPD** : Anonymisation et traÃ§abilitÃ© complÃ¨tes
- âœ… **IA** : Classification Ã©motionnelle opÃ©rationnelle
- âœ… **Interface** : Streamlit avec donnÃ©es rÃ©elles
- âœ… **Documentation** : ComplÃ¨te et Ã  jour
- âœ… **Tests** : Pipeline end-to-end validÃ©

**Le projet est prÃªt pour la prÃ©sentation au jury !** ğŸ¯âœ…

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. Consulter la documentation dans `docs/`
2. VÃ©rifier les logs dans `data/logs/`
3. Tester les composants avec `scripts/test_components_individual.py`
4. Consulter l'interface Streamlit pour le statut en temps rÃ©el